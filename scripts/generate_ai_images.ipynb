{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "!pip\n",
    "install - q\n",
    "diffusers\n",
    "transformers\n",
    "accelerate\n",
    "deepface\n",
    "pandas\n",
    "\n",
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "import os\n",
    "import pandas as pd\n",
    "from deepface import DeepFace\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using Device: {device}\")\n",
    "\n",
    "\n",
    "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)\n",
    "pipe = pipe.to(device)\n",
    "pipe.safety_checker = None  # Disable safety checker to speed up and avoid false positives\n",
    "\n",
    "ROLES = [\"doctor\", \"nurse\", \"teacher\", \"scientist\", \"chef\", \"artist\", \"builder\", \"driver\"]\n",
    "COUNT_PER_ROLE = 50\n",
    "OUTPUT_DIR = \"ai_images\"\n",
    "CSV_NAME = \"analysis_ai.csv\"\n",
    "\n",
    "print(f\"\\n Starting Generation: {COUNT_PER_ROLE * len(ROLES)} images total...\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "for role in ROLES:\n",
    "    role_dir = os.path.join(OUTPUT_DIR, role)\n",
    "    os.makedirs(role_dir, exist_ok=True)\n",
    "\n",
    "    for i in tqdm(range(COUNT_PER_ROLE), desc=f\"Generating {role.upper()}\"):\n",
    "        fname = f\"{role}_{i:03d}.png\"\n",
    "        path = os.path.join(role_dir, fname)\n",
    "\n",
    "        prompt = f\"a photo of a {role}, looking at camera, realistic, 8k\"\n",
    "        negative_prompt = \"cartoon, drawing, anime, illustration, ugly, deformed\"\n",
    "\n",
    "        image = pipe(prompt, negative_prompt=negative_prompt, width=512, height=512, num_inference_steps=25).images[0]\n",
    "        image.save(path)\n",
    "\n",
    "print(\"\\nGeneration Complete!\")\n",
    "\n",
    "# 5. Analyze with DeepFace\n",
    "print(\"\\nStarting Analysis...\")\n",
    "results = []\n",
    "\n",
    "for role in ROLES:\n",
    "    role_dir = os.path.join(OUTPUT_DIR, role)\n",
    "    images = [f for f in os.listdir(role_dir) if f.endswith(\".png\")]\n",
    "\n",
    "    for img in tqdm(images, desc=f\"Analyzing {role}\"):\n",
    "        full_path = os.path.join(role_dir, img)\n",
    "        try:\n",
    "            # Run DeepFace\n",
    "            obj = DeepFace.analyze(\n",
    "                img_path=full_path,\n",
    "                actions=['gender', 'race'],\n",
    "                detector_backend='opencv',\n",
    "                silent=True,\n",
    "                enforce_detection=False\n",
    "            )\n",
    "\n",
    "            res = obj[0]\n",
    "            gender = max(res['gender'], key=res['gender'].get)\n",
    "            race = res['dominant_race']\n",
    "            face_detected = True\n",
    "        except:\n",
    "            gender = \"unknown\"\n",
    "            race = \"unknown\"\n",
    "            face_detected = False\n",
    "\n",
    "        results.append({\n",
    "            \"image_id\": img,\n",
    "            \"role\": role,\n",
    "            \"face_detected\": face_detected,\n",
    "            \"gender\": gender,\n",
    "            \"race\": race\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(CSV_NAME, index=False)\n",
    "print(f\"\\nDONE! Saved to {CSV_NAME}\")"
   ],
   "id": "d63ce51c8528bba5"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
